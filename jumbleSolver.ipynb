{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a puzzle number 3\n",
      "\n",
      "Possible options:  [('dinky', 0)]\n",
      "\n",
      "Possible options:  [('agile', 0), ('galei', 0), ('agiel', 0)]\n",
      "\n",
      "Possible options:  [('encore', 0)]\n",
      "\n",
      "Possible options:  [('devout', 0)]\n",
      "Final Result:  [('addition',), ('toddling',), ('addition',)]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import itertools\n",
    "from itertools import product\n",
    "from itertools import permutations\n",
    "import pandas\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "def yieldPermutations(definition):\n",
    "    for t in product(*definition):\n",
    "        yield \"\".join(t)\n",
    "\n",
    "def checkWord(word):\n",
    "    return word in words\n",
    "\n",
    "def filterQuery(queryList):\n",
    "    filtered_query = []\n",
    "    for token in queryList:\n",
    "        for elem in nlp(token):\n",
    "            if elem.pos_ not in ['PRON', 'ADP', 'PROPN'] and not elem.tag_ in ['VBZ', 'VBD'] and not elem.is_stop and not elem.is_punct:\n",
    "                filtered_query.append(elem.text)\n",
    "    return filtered_query\n",
    "\n",
    "def filterWords(wordList):\n",
    "    filtered_wordList = []\n",
    "    for token in wordList:\n",
    "        for elem in nlp(token):\n",
    "            if elem.pos_ not in ['PRON', 'ADP'] and not elem.is_stop and not elem.is_punct:\n",
    "                filtered_wordList.append(elem.text)\n",
    "    return filtered_wordList\n",
    "\n",
    "def computeQueryList(puzzleId):\n",
    "    comment = df['Comment'][puzzleId]\n",
    "    question = df['Question'][puzzleId]\n",
    "    query = comment.lower()+question.lower()\n",
    "    list_new = query.split()\n",
    "    return filterQuery(list_new)\n",
    "\n",
    "def compareSimilarity(queryList, filteredList):\n",
    "    similarity_list = []\n",
    "    for token1 in queryList:\n",
    "        for token2 in filteredList:\n",
    "            if nlp(token1) and nlp(token2) and nlp(token1).vector_norm and nlp(token2).vector_norm:\n",
    "                similarity_list.append((token1, token2, nlp(token1).similarity(nlp(token2))))\n",
    "        \n",
    "    return list(sorted(similarity_list, key=lambda x: x[2], reverse = True))\n",
    "\n",
    "def probableWords(filteredList, puzzleId):\n",
    "    \n",
    "    #Checking contextual similarity of the word with the query\n",
    "    queryList = computeQueryList(puzzleId)\n",
    "    sorted_similarity_list = compareSimilarity(queryList, filteredList)\n",
    "    \n",
    "    #Picking top 50% of the values for computation\n",
    "    top_solutions = sorted_similarity_list[: int(len(sorted_similarity_list) * 0.2)]\n",
    "\n",
    "    probable_words = []\n",
    "    for each in top_solutions:\n",
    "        if each[1] not in probable_words:\n",
    "            probable_words.append(each[1])\n",
    "    return probable_words\n",
    "\n",
    "def remainingLetters(originalList, wordList):\n",
    "    res = [ele for ele in originalList] \n",
    "    for a in wordList: \n",
    "        if a in originalList: \n",
    "            res.remove(a) \n",
    "    return res\n",
    "\n",
    "def validWordCombinationGenerator(probableList, letters_list, reqWordLengths):\n",
    "    remaining_store = letters_list\n",
    "    resultList = []\n",
    "    \n",
    "    for token in probableList:\n",
    "        remaining_letters = remainingLetters(letters_list, list(token))\n",
    "\n",
    "        inter_remaining_store = remaining_letters\n",
    "        possibleWords = generateNLengthWords(remaining_letters, reqWordLengths[0], puzzleId)\n",
    "        if len(possibleWords) >=1 and not sorted((token, possibleWords[0])) in resultList:\n",
    "                resultList.append(sorted((token, possibleWords[0])))\n",
    "\n",
    "        if len(possibleWords)>0:\n",
    "            for each in possibleWords:\n",
    "                letters_list = inter_remaining_store\n",
    "                remaining_letters = remainingLetters(letters_list, list(each))\n",
    "                possible_words2 = generateNLengthWords(remaining_letters, reqWordLengths[0], puzzleId)\n",
    "                if len(possible_words2) >=1 and not sorted((token, each, possible_words2[0])) in resultList:\n",
    "                    resultList.append(sorted((token, each, possible_words2[0])))\n",
    "\n",
    "        letters_list = remaining_store\n",
    "    return resultList\n",
    "\n",
    "def generateNLengthWords(lettersList, wordLength, puzzleId):\n",
    "    pairs = [''.join(combo) for combo in itertools.permutations(lettersList, wordLength)]\n",
    "    \n",
    "    #Filtering to check if it is a valid english word and has positive frequency distrubtion from json dictionary\n",
    "    filtered_pairs = set(filter(lambda elem: checkWord(elem) and data[elem]>=0, pairs))\n",
    "    \n",
    "    # Filtering to eliminate punctuations, stop-words, irrelevant words based on POS\n",
    "    filtered_words = filterWords(filtered_pairs)\n",
    "    \n",
    "    #Sorting to have highest probable terms based on frequency distribution\n",
    "    sorted_filtered_list = list(sorted(filtered_words, key=lambda x: data[x]))\n",
    "    return probableWords(sorted_filtered_list, puzzleId)\n",
    "\n",
    "def generateValidCombinations(relatedList, lettersList, solutionWordLengths):\n",
    "    #finalSet = set()\n",
    "    finalList = []\n",
    "    for index in solutionWordLengths:\n",
    "        finalList.append(tuple(validWordCombinationGenerator(relatedList, lettersList, solutionWordLengths)))\n",
    "    \n",
    "    #finalSet = set(finalList)\n",
    "    return finalList\n",
    "\n",
    "def preProcessCsv(puzzleId):\n",
    "    jumbled_words = df['JumbledWords'][puzzleId].split(';')\n",
    "    jumbled_words = [x.strip() for x in jumbled_words]\n",
    "    return jumbled_words\n",
    "\n",
    "def preProcessWord(jumbledWord):\n",
    "    jumbledWord = jumbledWord.strip('\"''\")(').replace(\"'\", '').split(',')\n",
    "    letter_positions_str = jumbledWord[1][2:-1].split()       \n",
    "    return jumbledWord[0], list(map(int, letter_positions_str))\n",
    "\n",
    "def preProcessReqWordLength(puzzleId):\n",
    "    word_lengths_str = df['RequiredWordLengths'][puzzleId][1:-1].split()\n",
    "    return sorted(list(map(int, word_lengths_str)), reverse = True)\n",
    "    \n",
    "anagram_dict ={}\n",
    "\n",
    "\n",
    "# Opening JSON file\n",
    "with open('./freq_dict.json') as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "        df = pandas.read_csv('./puzzleData.csv')\n",
    "        puzzleId = int(input('Enter a puzzle number '))\n",
    "        \n",
    "        words = data.keys()\n",
    "\n",
    "        #creating list of anagrams as keys\n",
    "        anagram_keys = [''.join(sorted(word.strip().lower())) for word in list(words)]\n",
    "\n",
    "        #looping through 'data' dictionary to create anagaram_dict\n",
    "        for key, value in data.items():\n",
    "            new_key = ''.join(sorted(key))\n",
    "            if new_key in anagram_dict.keys():\n",
    "                anagram_dict[new_key].append((key, value))\n",
    "            else:\n",
    "                anagram_dict[new_key] = [(key, value)]\n",
    "\n",
    "        possible_options = []\n",
    "        endResultHintsList = []\n",
    "        endResultPossibleHintCombinations = []\n",
    "        endResultHintLetters = []\n",
    "        jumbled_words = preProcessCsv(puzzleId)\n",
    " \n",
    "        for jumbledWord in jumbled_words:\n",
    "            jumbledWord, letter_positions = preProcessWord(jumbledWord)\n",
    "            endResultPossibleHintCombinations = []\n",
    "            \n",
    "            #Check jumbled word\n",
    "            if ''.join(sorted(jumbledWord)) in anagram_dict.keys():\n",
    "                possible_options = anagram_dict[''.join(sorted(jumbledWord))]\n",
    "            else:\n",
    "                continue\n",
    "            print(\"\\nPossible options: \",  possible_options)\n",
    "       \n",
    "            #Retrieve all the positional hint letters\n",
    "            for option in possible_options:\n",
    "                endResultHintLetters = []\n",
    "                option_letters = list(option[0])\n",
    "                for position in letter_positions:\n",
    "                    endResultHintLetters.append(option_letters[position-1])                      \n",
    "                endResultPossibleHintCombinations.append(endResultHintLetters)\n",
    "            endResultHintsList.append(endResultPossibleHintCombinations)\n",
    "        \n",
    "        possible_combinations = list(itertools.product(*endResultHintsList))\n",
    "        finalResult = []\n",
    "        \n",
    "        for tuple_combination in possible_combinations:\n",
    "            #Permutations of letter lists\n",
    "            letters_list = [letter for arr in tuple_combination for letter in arr]\n",
    "\n",
    "            reqWords = preProcessReqWordLength(puzzleId)\n",
    "            initialList = tuple(generateNLengthWords(letters_list, reqWords[0], puzzleId))\n",
    "            \n",
    "            if len(reqWords) == 1:\n",
    "                finalResult.append(initialList)\n",
    "            else:\n",
    "                if len(generateValidCombinations(initialList, letters_list, reqWords[1:])) > 0:\n",
    "                    finalResult.append(generateValidCombinations(initialList, \n",
    "                              letters_list,\n",
    "                              reqWords[1:]))               \n",
    "                         \n",
    "        print('Final Result: ', finalResult)\n",
    "            \n",
    "\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
